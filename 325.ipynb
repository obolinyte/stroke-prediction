{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Machine Learning\n## Sprint 2: Gradient Boosted Trees & Feature Engineering\n## Part 5: Stroke Prediction Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Part\n\nCongrats!\nYou have reached the last Part of this Sprint.\nIn this Part, you will put what you learned during this and the previous Sprints into practice.\nAs the final assignment of this Sprint, you will train and deploy a machine learning models on the Stroke Prediction Dataset.\nYou will have to apply all that you have learned about training and deploying machine learning models to complete this task.\nOur expectation is that you'll use your own judgement how to perform the analysis and how to select the most important avenues of modeling, statistical testing, and exploration.\nYou'll have to iteratively try to find patterns in the data, raise hypotheses and use your data analysis skills to get answers.\n\n## Context\n\nImagine that you are a data analyst working for the The Johns Hopkins Hospital.\nYour team is asked to create a machine learning model, which could predict if the patient is likely to get a stroke - being able to determine, which patients have high stroke risk will allow your doctors to advice them and their families how to act in case of an emergency.\nAs you are about to start working on your project your team's manager approaches you with a request.\nShe has read an article that AI can predict all sorts of things that required dedicated sensors before - [Tesla doesn't use a rain sensor for its automatic wiper system](https://electrek.co/2019/10/14/tesla-deep-rain-neural-net-automatic-wipers/).\nFollowing the example of Elon Musk she proposes her brilliant idea to save money - to replace all blood pressure monitors, glucose monitor, and scales with AI.\nShe argues that this would save the hospital millions of dollars every year.\nShe wants you to create three additional machine learning models to predict the hypertension, average glucose level, and BMI of the patient.\nYou are not 100% convinced of this idea and try to explain why it won't work, but she is insistent and you promise to try anyway - this will give you a great opportunity to practice your new machine learning skills and have metrics about how accurate predictions for these variables can be using state-of-the-art machine learning models.\n\n## Objectives for this Part\n\n- Practice working with CSV files.\n- Practice performing EDA.\n- Practice applying statistical inference procedures.\n- Practice using various types of machine learning models.\n- Practice building ensembles of machine learning models.\n- Practice deploying machine learning models.\n- Practice visualizing data with Matplotlib & Seaborn.\n- Practice reading data, performing queries and filtering data.\n\n## Requirements\n\n- Download the data from [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset).\n- Perform exploratory data analysis. This should include creating statistical summaries and charts, testing for anomalies, checking for correlations and other relations between variables, and other EDA elements.\n- Perform statistical inference. This should include defining the target population, forming multiple statistical hypotheses and constructing confidence intervals, setting the significance levels, conducting z or t-tests for these hypotheses.\n- Apply various machine learning models to predict the stroke column using the all other features. This should include hyperparameter tuning, model ensembling, the analysis of model selection, and other methods.\n- In addition use machine learning to predict the hypertension, avg_glucose_level, and bmi columns. You should create a model predicting each of these variables, then a model for each pair of variables and finally a model predicting all three of these variables - all in all 7 models. You can use all remaining variables as features, except for stroke. This should include hyperparameter tuning, the analysis of model selection, and other methods.\n- Deploy all of these machine learning models. You are free to choose any deployment option that you like - you can deploy your models in a container (on your computer or on a server), do a serverless deployment on the cloud or even deploy serve it on the browser as a web app. These deployments don't have to be separate, as long as each model has its own endpoint.\n- Provide clear explanations in your notebook. Your explanations should inform the reader what you are trying to achieve, what results did you get, and what these results mean.\n- Provide suggestions about how your analysis can be improved.\n\n## Evaluation Criteria\n\n- Adherence to the requirements. How well did you meet the requirements?\n- Depth of your analysis. Did you just skim the surface or did you explored the dataset in depth?\n- Model's performance. How well did your model perform the predictions?\n- Visualization quality. Did you use charts effectively to visualize patterns in the data? Are your visualizations properly labeled? Did you use colors effectively? Did you adhere to the principle of proportional ink?\n- Code quality. Was your code well-structure? Did you use the appropriate levels of abstraction? Did you remove commented out and unused code? Did you adhere to the PEP8?\n- Code performance. Did you use the suitable algorithms and data structures to solve the problems?\n\n## Sample Correction Questions\n\nDuring a correction, you may get asked questions that test your understanding of covered topics.\n\n- What is wrong with preprocessing data before we run a hyperparameter search algorithm (e.g. randomized search) with cross validation?\n- What are the typical model deployment patterns? What are their advantages and disadvantages?\n- How hidden feedback loops affect machine learning models? Can you give an example of a hidden feedback loop?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
